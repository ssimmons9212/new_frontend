{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Lars\n",
    "\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wne = pd.read_csv(os.path.join(\"Data\", \"wne_test_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WINE</th>\n",
       "      <th>BODY</th>\n",
       "      <th>PH</th>\n",
       "      <th>ABV</th>\n",
       "      <th>WINE_CLASS</th>\n",
       "      <th>TANNIN</th>\n",
       "      <th>FAT</th>\n",
       "      <th>PROTEIN</th>\n",
       "      <th>CALORIES</th>\n",
       "      <th>SODIUM</th>\n",
       "      <th>CARBS</th>\n",
       "      <th>PROTEIN_main</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>FAT_CARB</th>\n",
       "      <th>FAT_PRO</th>\n",
       "      <th>PROTEIN_NEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>23.040000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>10.890000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.103385</td>\n",
       "      <td>0.269565</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.112373</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>2.193548</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.031681</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392477</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.758383</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WINE  BODY  PH  ABV  WINE_CLASS  TANNIN  FAT  PROTEIN  CALORIES  SODIUM  \\\n",
       "0     1     5   3  4.0           5       4  4.8      3.0       5.1     3.6   \n",
       "1     1     5   3  4.0           5       4  3.3      3.8       4.1     1.5   \n",
       "2     1     5   3  4.0           5       4  3.1      3.0       4.6     0.0   \n",
       "3     1     5   3  4.0           5       4  6.8      3.1       8.1     5.9   \n",
       "4     1     5   3  4.0           5       4  0.6      2.8       1.5     8.4   \n",
       "5     1     5   3  4.0           5       4  5.6      6.2       7.0     1.9   \n",
       "6     1     5   3  4.0           5       4  3.0      1.9       3.2     0.9   \n",
       "7     1     5   3  4.0           5       4  1.5      2.7       3.2     5.0   \n",
       "8     1     5   3  4.0           5       4  2.7      2.1       3.3     0.7   \n",
       "9     1     5   3  4.0           5       4  4.1      4.0       5.0    11.8   \n",
       "\n",
       "   CARBS  PROTEIN_main  Unnamed: 12  FAT_CARB   FAT_PRO  PROTEIN_NEW  \n",
       "0    0.5             1    23.040000  9.600000  1.600000          3.0  \n",
       "1    0.5             1    10.890000  6.600000  0.868421          3.8  \n",
       "2   11.5             2     1.103385  0.269565  1.033333          6.0  \n",
       "3   18.0             1     1.112373  0.377778  2.193548          3.1  \n",
       "4    0.5             1     0.360000  1.200000  0.214286          2.8  \n",
       "5    1.0             1     5.600000  5.600000  0.903226          6.2  \n",
       "6    1.0             1     3.000000  3.000000  1.578947          1.9  \n",
       "7   13.0             1     1.031681  0.115385  0.555556          2.7  \n",
       "8    3.0             1     1.392477  0.900000  1.285714          2.1  \n",
       "9    2.5             1     1.758383  1.640000  1.025000          4.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wne[\"FAT_CARB\"] = df_wne[\"FAT\"] / df_wne[\"CARBS\"]\n",
    "df_wne[\"FAT_PRO\"] = df_wne[\"FAT\"] / df_wne[\"PROTEIN\"]\n",
    "df_wne[\"PROTEIN_NEW\"] = df_wne[\"PROTEIN_main\"] * df_wne[\"PROTEIN\"]\n",
    "df_wne.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wne_holdout = pd.read_csv(os.path.join(\"Data\", \"wn_hldot.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WINE</th>\n",
       "      <th>BODY</th>\n",
       "      <th>PH</th>\n",
       "      <th>ABV</th>\n",
       "      <th>WINE_CLASS</th>\n",
       "      <th>TANNIN</th>\n",
       "      <th>FAT</th>\n",
       "      <th>PROTEIN</th>\n",
       "      <th>CALORIES</th>\n",
       "      <th>SODIUM</th>\n",
       "      <th>CARBS</th>\n",
       "      <th>PROTEIN_main</th>\n",
       "      <th>FAT_CARB</th>\n",
       "      <th>FAT_PRO</th>\n",
       "      <th>PROTEIN_NEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.97</td>\n",
       "      <td>6.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.18</td>\n",
       "      <td>5.80</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.18</td>\n",
       "      <td>5.80</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.37</td>\n",
       "      <td>6.90</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8.40</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.38</td>\n",
       "      <td>10.75</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.63</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.15</td>\n",
       "      <td>8.37</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.87</td>\n",
       "      <td>5.95</td>\n",
       "      <td>16.5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.187879</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.24</td>\n",
       "      <td>8.15</td>\n",
       "      <td>11.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.191304</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.75</td>\n",
       "      <td>14.46</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>32.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.14</td>\n",
       "      <td>34.09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    WINE  BODY  PH  ABV  WINE_CLASS  TANNIN   FAT  PROTEIN  CALORIES  SODIUM  \\\n",
       "0      1     5   3  4.0           5       4  2.00      1.5      2.32    0.64   \n",
       "1      1     5   3  4.0           5       4  0.90      4.3      2.97    6.00   \n",
       "2      2     5   3  4.0           5       3  3.00      2.0      4.18    5.80   \n",
       "3      2     5   3  4.0           5       3  2.70      2.1      3.34    0.75   \n",
       "4      3     5   2  3.5           5       2  3.00      2.0      4.18    5.80   \n",
       "5      4     4   3  4.0           5       4  2.20      3.1      4.37    6.90   \n",
       "6      5     3   4  3.0           4       2  8.40      7.0     10.38   10.75   \n",
       "7      7     2   2  3.0           3       0  0.45      1.7      4.17    0.37   \n",
       "8      8     3   3  4.0           4       0  0.90      2.9      3.17    3.63   \n",
       "9      9     2   5  3.0           3       0  0.80      2.3      2.15    8.37   \n",
       "10    10     1   5  1.0           3       0  3.10      0.8      3.87    5.95   \n",
       "11    11     3   1  4.0           4       0  2.20      1.5      3.24    8.15   \n",
       "12    11     3   1  4.0           4       0  2.70      4.1      6.75   14.46   \n",
       "13     6     5   3  4.0           5       2  3.60      3.0      5.14   34.09   \n",
       "\n",
       "    CARBS  PROTEIN_main  FAT_CARB   FAT_PRO  PROTEIN_NEW  \n",
       "0     2.5             1  0.800000  1.333333          1.5  \n",
       "1    10.0             1  0.090000  0.209302          4.3  \n",
       "2     7.0             1  0.428571  1.500000          2.0  \n",
       "3     3.0             1  0.900000  1.285714          2.1  \n",
       "4     7.0             1  0.428571  1.500000          2.0  \n",
       "5     9.0             1  0.244444  0.709677          3.1  \n",
       "6     6.0             3  1.400000  1.200000         21.0  \n",
       "7    45.0             7  0.010000  0.264706         11.9  \n",
       "8    16.0             3  0.056250  0.310345          8.7  \n",
       "9    10.0             5  0.080000  0.347826         11.5  \n",
       "10   16.5             9  0.187879  3.875000          7.2  \n",
       "11   11.5             3  0.191304  1.466667          4.5  \n",
       "12   40.0             8  0.067500  0.658537         32.8  \n",
       "13    2.0             1  1.800000  1.200000          3.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wne_holdout[\"FAT_CARB\"] = df_wne_holdout[\"FAT\"] / df_wne_holdout[\"CARBS\"]\n",
    "df_wne_holdout[\"FAT_PRO\"] = df_wne_holdout[\"FAT\"] / df_wne_holdout[\"PROTEIN\"]\n",
    "df_wne_holdout[\"PROTEIN_NEW\"] = (\n",
    "    df_wne_holdout[\"PROTEIN_main\"] * df_wne_holdout[\"PROTEIN\"]\n",
    ")\n",
    "df_wne_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_wne[\n",
    "    [\"WINE_CLASS\", \"PROTEIN\", \"PROTEIN_main\", \"CALORIES\", \"SODIUM\", \"FAT_PRO\"]\n",
    "].values\n",
    "# X = x.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_wne[\"WINE\"].values\n",
    "# y = Y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST TRAIN SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=20, random_state=1234, shuffle=True)\n",
      "TRAIN: [  0   1   2   3   4   5   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  28  30  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56\n",
      "  58  59  60  61  62  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  92  93  94  95\n",
      "  96  97  98  99 100 101 102 103 104 105 106 107 108 110 111 112 113 114\n",
      " 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 142 143 145 146 147 148 149 150 151] TEST: [  6  27  29  57  63  91 109 144]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  41  42  43  44  45  46  47  49  50  52  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  78  80  81  82  83  84  85  86  87  88  89  90  91  92  94  95\n",
      "  96  97  98  99 100 101 102 103 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133\n",
      " 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151] TEST: [ 40  48  51  77  79  93 104 117]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  89  90  91  92  93\n",
      "  95  96  97  98  99 100 101 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 141 142 143 144 145 146 147 148 149 150 151] TEST: [ 11  17  54  88  94 102 103 140]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  26  27  28  29  30  31  32  33  34  36  37\n",
      "  38  39  40  41  42  44  45  46  47  48  49  50  51  52  53  54  55  56\n",
      "  57  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75\n",
      "  76  77  78  79  80  81  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  99 100 101 102 103 104 105 106 107 108 109 111 112 113 114\n",
      " 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151] TEST: [ 25  35  43  58  82  98 110 135]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  40  41  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 101 102 103 104 105 106 107 108 109 110 112 113\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 149 150 151] TEST: [ 39  42  59  78 100 111 132 148]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   9  10  11  12  13  14  15  16  17  18\n",
      "  19  21  23  25  26  27  28  29  30  31  32  33  34  35  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  69  70  71  72  73  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 120 121 122 123 124 125 126 127 128 129 130 131 132 133\n",
      " 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151] TEST: [  8  20  22  24  36  68  74 119]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 106 107 109 110 111\n",
      " 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      " 130 131 132 133 134 135 136 138 139 140 141 142 143 144 146 148 150 151] TEST: [  9  32 105 108 137 145 147 149]\n",
      "TRAIN: [  0   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  62  63  64  65  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98 100 101 102 103 104 105 106 107 108 109 110 111\n",
      " 112 113 114 115 116 117 118 119 120 121 122 123 124 126 127 128 130 131\n",
      " 132 133 134 135 136 137 138 139 140 143 144 145 146 147 148 149 150 151] TEST: [  1  61  66  99 125 129 141 142]\n",
      "TRAIN: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  22  23  24  25  26  27  28  29  30  31  32  34  35  36  37  38\n",
      "  39  40  41  42  43  44  45  46  47  48  49  50  51  53  54  55  56  57\n",
      "  58  59  60  61  63  65  66  67  68  69  70  71  72  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151] TEST: [  0  21  33  52  62  64  73 136]\n",
      "TRAIN: [  0   1   2   3   5   6   7   8   9  11  12  13  14  16  17  18  19  20\n",
      "  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  56  57\n",
      "  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75\n",
      "  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111\n",
      " 112 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 131\n",
      " 132 134 135 136 137 138 139 140 141 142 143 144 145 147 148 149 150 151] TEST: [  4  10  15  55 113 130 133 146]\n",
      "TRAIN: [  0   1   2   3   4   6   8   9  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  86  87  88  89  90  91  93  94\n",
      "  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112\n",
      " 113 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n",
      " 132 133 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 151] TEST: [  5   7  67  85  92 114 134 150]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  45  46  47  48  50  51  52  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  84  85  87  88  89  91  92  93  94  95\n",
      "  96  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150] TEST: [ 18  44  49  83  86  90  97 151]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  42  43  44  46  47  48  49  50  51  52  53  54  55  57\n",
      "  58  59  60  61  62  63  64  65  66  67  68  69  71  73  74  75  76  77\n",
      "  78  79  80  81  82  83  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n",
      " 151] TEST: [16 41 45 56 70 72 84]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  90  91\n",
      "  92  93  94  97  98  99 100 102 103 104 105 106 107 108 109 110 111 112\n",
      " 113 114 115 116 117 118 119 120 121 122 123 124 125 127 128 129 130 131\n",
      " 132 133 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150\n",
      " 151] TEST: [ 31  89  95  96 101 126 139]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  47  48  49  50  51  52  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102 103 104 105 107 108 109 110 111 112\n",
      " 113 114 115 116 117 118 119 120 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n",
      " 151] TEST: [ 13  28  46  87 106 121 122]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  61  62  63  64  65  66  67  68  69  70  72  73  74\n",
      "  75  76  77  78  79  80  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102 103 104 105 106 108 109 110 111 112\n",
      " 113 114 116 117 118 119 120 121 122 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n",
      " 151] TEST: [ 14  60  71  81 107 115 123]\n",
      "TRAIN: [  0   1   4   5   6   7   8   9  10  11  13  14  15  16  17  18  20  21\n",
      "  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39\n",
      "  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57\n",
      "  58  59  60  61  62  63  64  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112\n",
      " 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n",
      " 132 133 134 135 136 137 139 140 141 142 143 144 145 146 147 148 149 150\n",
      " 151] TEST: [  2   3  12  19  65 131 138]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  35  36\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  51  52  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112\n",
      " 113 114 115 116 117 118 119 120 121 122 123 124 125 126 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n",
      " 151] TEST: [ 34  37  50  75  76 127 128]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  70  71  72  73\n",
      "  74  75  76  77  78  79  81  82  83  84  85  86  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110\n",
      " 111 113 114 115 116 117 119 121 122 123 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150\n",
      " 151] TEST: [ 26  69  80 112 118 120 124]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  24  25  26  27  28  29  31  32  33  34  35  36  37\n",
      "  39  40  41  42  43  44  45  46  48  49  50  51  52  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112\n",
      " 113 114 115 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n",
      " 132 133 134 135 136 137 138 139 140 141 142 144 145 146 147 148 149 150\n",
      " 151] TEST: [ 23  30  38  47  53 116 143]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=20, shuffle=True, random_state=1234)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.175, random_state=7456\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest, GaussianNB, Linear Regression, Weighted RF, NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       0.00      0.00      0.00         0\n",
      "           9       1.00      1.00      1.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.43         7\n",
      "   macro avg       0.29      0.29      0.29         7\n",
      "weighted avg       0.43      0.43      0.43         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ssimmons\\.conda\\envs\\python 3_7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ssimmons\\.conda\\envs\\python 3_7\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# clf = MLPClassifier(\n",
    "#     solver=\"sgd\", alpha=1e-2, max_iter=500, hidden_layer_sizes=(175,), random_state=1\n",
    "# )\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# lrr = Ridge()\n",
    "# lrr.fit(X_train, y_train)\n",
    "# y_pred = lrr.predict(X_test)\n",
    "# print(r2_score(y_test, y_pred))\n",
    "\n",
    "# lr_wne = LinearRegression()\n",
    "# lr_wne.fit(X_train, y_train)\n",
    "# y_pred = lr_wne.predict(X_test)\n",
    "# print(r2_score(y_test, y_pred))\n",
    "\n",
    "# lar_wne = Lars()\n",
    "# lar_wne.fit(X_train, y_train)\n",
    "# y_pred = lar_wne.predict(X_test)\n",
    "# print(r2_score(y_test, y_pred))\n",
    "\n",
    "# nbm_wne = MultinomialNB()\n",
    "# nbm_wne.fit(X_train, y_train)\n",
    "# y_pred = nbm_wne.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# nb_wne = GaussianNB()\n",
    "# nb_wne.fit(X_train, y_train)\n",
    "# y_pred = nb_wne.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "wrf_wne = RandomForestClassifier(class_weight=\"balanced\")\n",
    "wrf_wne.fit(X_train, y_train)\n",
    "y_pred = wrf_wne.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=\"warn\"))\n",
    "\n",
    "# rf_wne = RandomForestClassifier()\n",
    "# rf_wne.fit(X_train, y_train)\n",
    "# y_pred = rf_wne.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wrf_wne.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump(lrr, \"lrr.joblib\")\n",
    "\n",
    "# dump(lr_wne, \"lr_wne.joblib\")\n",
    "\n",
    "# dump(lar_wne, \"lar_wne.joblib\")\n",
    "\n",
    "# dump(nb_wne, \"nb_wne.joblib\")\n",
    "\n",
    "# dump(nbm_wne, \"nbm_wne.joblib\")\n",
    "\n",
    "dump(wrf_wne, \"wrf_wne.joblib\")\n",
    "\n",
    "# dump(rf_wne, \"rf_wne.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_wne_holdout[\n",
    "    [\"WINE_CLASS\", \"PROTEIN\", \"PROTEIN_main\", \"CALORIES\", \"SODIUM\", \"FAT_PRO\"]\n",
    "].values\n",
    "Y = df_wne_holdout[\"WINE\"].values\n",
    "y = Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg = load(\"nb_wne.joblib\")\n",
    "\n",
    "# reg = load(\"nb.joblib\")\n",
    "\n",
    "# reg = load(\"rf_wne.joblib\")\n",
    "\n",
    "reg = load(\"wrf_wne.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  2  2  2  6  8  7  8  9 10  8 11  2]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WINE</th>\n",
       "      <th>WINE_PRED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    WINE  WINE_PRED\n",
       "0      1          2\n",
       "1      1          3\n",
       "2      2          2\n",
       "3      2          2\n",
       "4      3          2\n",
       "5      4          6\n",
       "6      5          8\n",
       "7      7          7\n",
       "8      8          8\n",
       "9      9          9\n",
       "10    10         10\n",
       "11    11          8\n",
       "12    11         11\n",
       "13     6          2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_pred = pd.DataFrame(prediction)\n",
    "\n",
    "# df_pred.head(15)\n",
    "# df_pred.rename(columns={0: \"Predicted Bo_Ft\"})\n",
    "df_wne_holdout[\"WINE_PRED\"] = prediction.astype(int)\n",
    "df_wne_holdout[[\"WINE\", \"WINE_PRED\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax1 = df_wne_holdout.plot.scatter(x=\"WINE\", y=\"WINE_PRED\", c=\"DarkBlue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
